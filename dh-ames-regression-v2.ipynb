{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python","metadata":{"_uuid":"91ea2703-ccbe-4b27-b340-9cf48eaa1ac0","_cell_guid":"d0bf39f0-058d-42ba-94f7-e77928c38244","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-11T07:53:55.389071Z","iopub.execute_input":"2022-03-11T07:53:55.389529Z","iopub.status.idle":"2022-03-11T07:53:55.39373Z","shell.execute_reply.started":"2022-03-11T07:53:55.389492Z","shell.execute_reply":"2022-03-11T07:53:55.393072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport warnings\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom scipy.stats import skew, kurtosis, boxcox_normmax\nfrom scipy.special import boxcox1p\n\nfrom IPython.display import display\nfrom pandas.api.types import CategoricalDtype\n\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\n# Establish File System location\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Note from Kaggle\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiond\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\n\n# Mute warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.401977Z","iopub.execute_input":"2022-03-11T07:53:55.402265Z","iopub.status.idle":"2022-03-11T07:53:55.41938Z","shell.execute_reply.started":"2022-03-11T07:53:55.402235Z","shell.execute_reply":"2022-03-11T07:53:55.418517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Models\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import VotingRegressor\nfrom mlxtend.regressor import StackingCVRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n# Stats\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p, boxcox\nfrom scipy.stats import boxcox_normmax,yeojohnson\n\n# Misc\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\n\n# Interpretability \nfrom pdpbox import pdp, get_dataset, info_plots\nimport shap\nimport eli5\nfrom eli5.sklearn import PermutationImportance","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.420884Z","iopub.execute_input":"2022-03-11T07:53:55.421284Z","iopub.status.idle":"2022-03-11T07:53:55.433046Z","shell.execute_reply.started":"2022-03-11T07:53:55.421254Z","shell.execute_reply":"2022-03-11T07:53:55.432293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--- \n---\n# Outline for Refactoring Code","metadata":{}},{"cell_type":"markdown","source":"## load Raw Data\n## Preprocessing\n    * impute\n    * clean\n    * encode\n\n## Feature Engineering\n    * optional normalization\n\n## Train Individual Models\n    * Linear Based\n    * Tree-like\n    * XGboost-like\n    * Stacked\n    \n## Blended Model\n    * Is there a way to cluster\n    \n## Machine Interpretability \n    * final blended model\n    * most effective individual models\n\n## Presentation\n    * possible application of interpreted models\n    \n---\n---","metadata":{}},{"cell_type":"code","source":"def load_data():\n    # Read data\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = clean(df)\n    df = encode(df)\n    df = impute_simple(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test\n\n\ndef load_data_combined():\n    # Read data\n    #../input/house-prices-advanced-regression-techniques/test.csv\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    return pd.concat([df_train, df_test])\n\ndef load_data_simple(): \n    # Read data\n    #../input/house-prices-advanced-regression-techniques/test.csv\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    return df_train, df_test\n\ndef reform_train_test_split(df_combined):\n    # Read data\n    #../input/house-prices-advanced-regression-techniques/test.csv\n    data_dir = Path(\"../input/house-prices-advanced-regression-techniques/\")\n    df_train = pd.read_csv(data_dir / \"train.csv\", index_col=\"Id\")\n    df_test = pd.read_csv(data_dir / \"test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    df_train = df_combined.loc[df_train.index, :]\n    df_test = df_combined.loc[df_test.index, :]\n    return df_train, df_test","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.434348Z","iopub.execute_input":"2022-03-11T07:53:55.434744Z","iopub.status.idle":"2022-03-11T07:53:55.453858Z","shell.execute_reply.started":"2022-03-11T07:53:55.434698Z","shell.execute_reply":"2022-03-11T07:53:55.453136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(df):\n    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\": \"BrkComm\"})\n    # Some values of GarageYrBlt are corrupt, so we'll replace them\n    # with the year the house was built\n    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n    # Names beginning with numbers are awkward to work with\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    }, inplace=True,\n    )\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.485634Z","iopub.execute_input":"2022-03-11T07:53:55.486481Z","iopub.status.idle":"2022-03-11T07:53:55.492566Z","shell.execute_reply.started":"2022-03-11T07:53:55.48644Z","shell.execute_reply":"2022-03-11T07:53:55.491868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute_simple(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.494186Z","iopub.execute_input":"2022-03-11T07:53:55.494432Z","iopub.status.idle":"2022-03-11T07:53:55.511051Z","shell.execute_reply.started":"2022-03-11T07:53:55.494402Z","shell.execute_reply":"2022-03-11T07:53:55.510225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------\n# Normalize Numerical Variables that do not originally have a gaussian (normal) distribution\n\ndef normalize_numerics(df, skew_cutoff=0.5):\n    '''\n    Finds Features with large skewness and applies box-cox transformation\n    '''\n    X = df.copy()\n    numeric_columns = X.select_dtypes([\"number\"]).columns\n    skew_feats = X[numeric_columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n    \n    too_skew = skew_feats[skew_feats > skew_cutoff].index\n    \n    # normalize each of the features with high skew with scipy boxcox \n    for s in too_skew:\n        X[s] = boxcox1p(X[s], boxcox_normmax(X[s] + 1))\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.512222Z","iopub.execute_input":"2022-03-11T07:53:55.51244Z","iopub.status.idle":"2022-03-11T07:53:55.524337Z","shell.execute_reply.started":"2022-03-11T07:53:55.512413Z","shell.execute_reply":"2022-03-11T07:53:55.523702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_skew_cols(df):\n    X = df.copy()\n    numeric_columns = X.select_dtypes([\"number\"]).columns\n    skew_feats = X[numeric_columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n    return skew_feats","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.525544Z","iopub.execute_input":"2022-03-11T07:53:55.525824Z","iopub.status.idle":"2022-03-11T07:53:55.538434Z","shell.execute_reply.started":"2022-03-11T07:53:55.525793Z","shell.execute_reply":"2022-03-11T07:53:55.537714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def de_skew_yeo(df):\n    skews = find_skew_cols(df)\n    skew_check = skews[skews > 0.5].index.tolist()\n    \n    for s in skew_check: \n        df[s] = yeojohnson(df[s])[0]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.5403Z","iopub.execute_input":"2022-03-11T07:53:55.540563Z","iopub.status.idle":"2022-03-11T07:53:55.552289Z","shell.execute_reply.started":"2022-03-11T07:53:55.540531Z","shell.execute_reply":"2022-03-11T07:53:55.551324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding for tree-based models\ndef label_encode_manual(df):\n    '''tested: passing'''\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] =  X[colname].cat.codes\n        \n    return X\n\n# label encoding using sklearn module LabelEncoder\ndef label_encode_sk(df):\n    '''tested: passing'''\n    X = df.copy()\n    categorical_columns = X.select_dtypes([\"category\"]).columns\n    \n    le = LabelEncoder()\n    X[categorical_columns] = X[categorical_columns].apply(lambda x: le.fit_transform(x))\n    return X\n\n# One Hot encoding for linear regression based models, and svm\ndef one_hot_encode_pd(df):\n    '''tested: passing'''\n    X = df.copy()\n    # for now we just use all categorical variables\n    cols_for_one_hot = X.select_dtypes([\"category\"]).columns.tolist()\n        \n    X_ohe = pd.get_dummies(X, columns=cols_for_one_hot, prefix=cols_for_one_hot, drop_first=True)\n    #X = X.drop(cols_for_one_hot)\n    #X = pd.concat((X,X_ohe), axis=1)\n    return X_ohe \n        \ndef one_hot_encode_sk(df):\n    '''tested: passing'''\n    X = df.copy()\n    cols_for_one_hot = X.select_dtypes([\"category\"]).columns\n    \n    ohe = OneHotEncoder()\n    X[cols_for_one_hot] = X[cols_for_one_hot].apply(lambda x: ohe.fit_transform(x))\n    \n    return X\n\ndef apply_standard_scaler(df):\n    X = df.copy","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.553577Z","iopub.execute_input":"2022-03-11T07:53:55.553861Z","iopub.status.idle":"2022-03-11T07:53:55.565895Z","shell.execute_reply.started":"2022-03-11T07:53:55.55383Z","shell.execute_reply":"2022-03-11T07:53:55.565031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------\n# Encode\n\n# The numeric features are already encoded correctly (`float` for\n# continuous, `int` for discrete), but the categoricals we'll need to\n# do ourselves. Note in particular, that the `MSSubClass` feature is\n# read as an `int` type, but is actually a (nominative) categorical.\n\n# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Alley\", \"LandContour\", \"LotConfig\", \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n\n\n# The ordinal (ordered) categorical features \n\n# Pandas calls the categories \"levels\"\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values\n# DH comment - this concatenates none - the pattern is simple and clever remember for the future\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\n\nfeatures_ord = [key for key in ordered_levels.keys()]\nfeatures_cat = features_ord + features_nom\n\n# DH Comment = the df[].cat.*     functions below are new. remember their usefulness\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name].cat.add_categories(\"None\", inplace=True)\n    # Ordinal categories\n    # DH comment - how to apply the Ordinal Ordering\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                  ordered=True))\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:55.567333Z","iopub.execute_input":"2022-03-11T07:53:55.567778Z","iopub.status.idle":"2022-03-11T07:53:55.585844Z","shell.execute_reply.started":"2022-03-11T07:53:55.567644Z","shell.execute_reply":"2022-03-11T07:53:55.585056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --------------------------\n# Data Processing Utility Functions\ndef preprocess_data(df):\n    df = clean(df)\n    df = encode(df)\n    df = impute_simple(df)\n    return df\n        \ndef load_and_preproc_data(type='basic'): \n    if type=='basic':\n        df_1 = load_data_combined()\n        df_1 = preprocess_data(df_1)\n        df_train, df_test = reform_train_test_split(df_1)\n        return df_train, df_test\n    \n    if type=='tt_split':\n        df, _ = load_data()\n        df = preprocess_data(df)\n        \n        df = clean(df)\n        df = encode(df)\n        df = impute_simple(df)\n        \n        y = df['SalePrice']\n        df = df.drop(['SalePrice'], axis=1)\n        \n        X_tn, X_tt, y_tn, y_tt = train_test_split(df, y, test_size=0.2, random_state=42)\n        return X_tn, X_tt, y_tn, y_tt\n    #active\n    else:\n        raise ValueError\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:17:04.562315Z","iopub.execute_input":"2022-03-11T08:17:04.562581Z","iopub.status.idle":"2022-03-11T08:17:04.571244Z","shell.execute_reply.started":"2022-03-11T08:17:04.562553Z","shell.execute_reply":"2022-03-11T08:17:04.570596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n---\n# Feature Engineering","metadata":{}},{"cell_type":"code","source":"\ndef score_dataset(X, y, model=XGBRegressor(), enc=True, trans_targ=True):\n    # Label encoding for categoricals\n    #\n    # Label encoding is good for XGBoost and RandomForest, but one-hot\n    # would be better for models like Lasso or Ridge. The `cat.codes`\n    # attribute holds the category levels.\n    if enc:\n        for colname in X.select_dtypes([\"category\"]):\n            X[colname] = X[colname].cat.codes\n    \n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    y = np.log(y) if trans_targ else y\n    \n    score = cross_val_score(\n            model, X, y, cv=5, scoring=\"neg_mean_squared_error\"\n        )\n    \n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.249495Z","iopub.execute_input":"2022-03-11T07:53:56.250348Z","iopub.status.idle":"2022-03-11T07:53:56.25719Z","shell.execute_reply.started":"2022-03-11T07:53:56.250294Z","shell.execute_reply":"2022-03-11T07:53:56.256295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------------------------\n# Baseline Scoring: for later comparison \ndef get_baseline_xgb_score():\n    df_train, df_test = load_and_preproc_data()\n\n    X = df_train.copy()\n    y = X.pop(\"SalePrice\")\n\n    baseline_score = score_dataset(X, y)\n    print(f\"Baseline XGB score: {baseline_score:.5f} RMSLE\")","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.258795Z","iopub.execute_input":"2022-03-11T07:53:56.259057Z","iopub.status.idle":"2022-03-11T07:53:56.273746Z","shell.execute_reply.started":"2022-03-11T07:53:56.259027Z","shell.execute_reply":"2022-03-11T07:53:56.272982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_baseline_xgb_score()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.274836Z","iopub.execute_input":"2022-03-11T07:53:56.27529Z","iopub.status.idle":"2022-03-11T07:53:56.566629Z","shell.execute_reply.started":"2022-03-11T07:53:56.275253Z","shell.execute_reply":"2022-03-11T07:53:56.565616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------\n# Mutual Information\n\ndef make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n    \n#look at the feature scores\n# X = df_train.copy()\n# y = X.pop(\"SalePrice\")\n\n# mi_scores = make_mi_scores(X, y)\n# mi_scores","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.568112Z","iopub.execute_input":"2022-03-11T07:53:56.568364Z","iopub.status.idle":"2022-03-11T07:53:56.578736Z","shell.execute_reply.started":"2022-03-11T07:53:56.568333Z","shell.execute_reply":"2022-03-11T07:53:56.5777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_uninformative(df, mi_scores):\n    return df.loc[:, mi_scores > 0.0]","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.581286Z","iopub.execute_input":"2022-03-11T07:53:56.581551Z","iopub.status.idle":"2022-03-11T07:53:56.590141Z","shell.execute_reply.started":"2022-03-11T07:53:56.581519Z","shell.execute_reply":"2022-03-11T07:53:56.589421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_drop_uninformative():\n    X_train = df_train.copy()\n    y_train = X_train.pop(\"SalePrice\")\n    X_train = drop_uninformative(X_train, mi_scores)\n\n# score_dataset(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.591271Z","iopub.execute_input":"2022-03-11T07:53:56.592107Z","iopub.status.idle":"2022-03-11T07:53:56.603732Z","shell.execute_reply.started":"2022-03-11T07:53:56.592022Z","shell.execute_reply":"2022-03-11T07:53:56.602819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Our Own Features","metadata":{}},{"cell_type":"code","source":"# -----------------------\n# Mathematical Transforms\n\ndef mathematical_transforms(df):\n    X = pd.DataFrame()\n    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n    return X\n    \ndef interactions(df):\n    X = pd.get_dummies(df.BldgType, prefix=\"Bldg\")\n    X = X.mul(df.GrLivArea, axis=0)\n    return X\n\ndef porch_counts(df):\n    X = pd.DataFrame()\n    X[\"PorchTypes\"] = df[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"Threeseasonporch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis='columns')\n    return X\n\ndef class_break_down(df):\n    X = pd.DataFrame()\n    X[\"MSClass\"] = df.MSSubClass.str.split(\"_\",n=1, expand=True)[0]\n    return X\n\ndef group_transforms(df):\n    X = pd.DataFrame()\n    X[\"MedNgbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.605296Z","iopub.execute_input":"2022-03-11T07:53:56.605839Z","iopub.status.idle":"2022-03-11T07:53:56.61739Z","shell.execute_reply.started":"2022-03-11T07:53:56.605798Z","shell.execute_reply":"2022-03-11T07:53:56.6165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --------------------------------\n# Clustering Features\n\ncluster_features = [\n    \"LotArea\",\n    \"TotalBsmtSF\",\n    \"FirstFlrSF\",\n    \"SecondFlrSF\",\n    \"GrLivArea\",\n]\n\ndef cluster_labels(df, features, n_clusters):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    \n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_new = pd.DataFrame()\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    return X_new\n\ndef cluster_distance(df, features, n_clusters=20): \n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0))/ X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n    X_clustered = kmeans.fit_transform(X_scaled)\n    X_clustered = pd.DataFrame(\n        X_clustered, columns=[f\"Centroid_{i}\" for i in range(X_clustered.shape[1])]\n    )\n    return X_clustered\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.618999Z","iopub.execute_input":"2022-03-11T07:53:56.619471Z","iopub.status.idle":"2022-03-11T07:53:56.632498Z","shell.execute_reply.started":"2022-03-11T07:53:56.619427Z","shell.execute_reply":"2022-03-11T07:53:56.631789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------\n# Principal Component Analysis\n\n#--------------------------------\n# Utility Functions for creating the principal components\ndef apply_pca(X, standardize=True):\n    # standardize the original features\n    if standardize:\n        X = (X - X.mean(axis=0)) / X.std(axis=0)\n    # Create Principal components\n    pca = PCA()\n    X_pca = pca.fit_transform(X)\n    # Convert to dataframe\n    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n    X_pca = pd.DataFrame(X_pca, columns=component_names)\n    # Create loadings\n    loadings = pd.DataFrame(\n        pca.components_.T, # transpose the matrix of loadings\n        columns=component_names, # the columns are the principal components\n        index=X.columns, # and the rows are the original features\n    )\n    return pca, X_pca, loadings\n\ndef plot_variance(pcs, width=8, dpi=100):\n        # Create figure\n    fig, axs = plt.subplots(1, 2)\n    n = pca.n_components_\n    grid = np.arange(1, n + 1)\n    # Explained variance\n    evr = pca.explained_variance_ratio_\n    axs[0].bar(grid, evr)\n    axs[0].set(\n        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n    )\n    # Cumulative Variance\n    cv = np.cumsum(evr)\n    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n    axs[1].set(\n        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n    )\n    # Set up figure\n    fig.set(figwidth=8, dpi=100)\n    return axs","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.633828Z","iopub.execute_input":"2022-03-11T07:53:56.634869Z","iopub.status.idle":"2022-03-11T07:53:56.653051Z","shell.execute_reply.started":"2022-03-11T07:53:56.634821Z","shell.execute_reply":"2022-03-11T07:53:56.652315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pca_feature_names():\n    pca_features = [\n        \"GarageArea\",\n        \"YearRemodAdd\",\n        \"TotalBsmtSF\",\n        \"GrLivArea\",\n    ]\n    return pca_features\n\ndef pca_driven_features(df):\n    X = pd.DataFrame()\n    X[\"GrLiv+TotalBsmtSF\"] = df.GrLivArea + df.TotalBsmtSF\n    X[\"YrRemod*TotalBsmtSF\"] = df.YearRemodAdd * df.TotalBsmtSF\n    return X\n\ndef pca_components(df, features):\n    X = df.loc[:, features]\n    t0, X_pca, t_1 = apply_pca(X)\n    return X_pca","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.654365Z","iopub.execute_input":"2022-03-11T07:53:56.654922Z","iopub.status.idle":"2022-03-11T07:53:56.67026Z","shell.execute_reply.started":"2022-03-11T07:53:56.654877Z","shell.execute_reply":"2022-03-11T07:53:56.669414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def indicate_outliers(df):\n    X_new = pd.DataFrame()\n    X_new[\"Outlier\"] = (df.Neighborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n    \n    # outlier masks\n    grliv_mask = (df['GrLivArea'] > 4000) & (X_new[\"Outlier\"] == False)\n    \n    # apply masks\n    X_new.loc[grliv_mask, \"Outlier\"] = True\n    \n    # convert bool to int\n    X_new[\"Outlier\"] = np.where(X_new[\"Outlier\"]==True, 1, 0)\n    return X_new","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.67306Z","iopub.execute_input":"2022-03-11T07:53:56.673433Z","iopub.status.idle":"2022-03-11T07:53:56.686408Z","shell.execute_reply.started":"2022-03-11T07:53:56.673388Z","shell.execute_reply":"2022-03-11T07:53:56.685238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    sns.clustermap(\n        df.corr(method),\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\n#corrplot(df_train, annot=None)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.68835Z","iopub.execute_input":"2022-03-11T07:53:56.689239Z","iopub.status.idle":"2022-03-11T07:53:56.704771Z","shell.execute_reply.started":"2022-03-11T07:53:56.689185Z","shell.execute_reply":"2022-03-11T07:53:56.703562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------\n# Target Encoding\nclass CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.70892Z","iopub.execute_input":"2022-03-11T07:53:56.709592Z","iopub.status.idle":"2022-03-11T07:53:56.726533Z","shell.execute_reply.started":"2022-03-11T07:53:56.709543Z","shell.execute_reply":"2022-03-11T07:53:56.72521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from category_encoders import CatBoostEncoder, MEstimateEncoder\n\ndef test_category_encoder():\n    X, X_test = load_data_simple()\n    encoder_me = CrossFoldEncoder(MEstimateEncoder, m=1)\n    encoder_cbe = CrossFoldEncoder(CatBoostEncoder, a=2)\n\n    X_encoded = encoder_cbe.fit_transform(X, y, cols=[\"MSSubClass\"])\n    X = X.join(encoder_cbe.fit_transform(X, y, cols=[\"MSSubClass\"]))\n    display(X['MSSubClass'])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.732747Z","iopub.execute_input":"2022-03-11T07:53:56.733498Z","iopub.status.idle":"2022-03-11T07:53:56.747475Z","shell.execute_reply.started":"2022-03-11T07:53:56.73345Z","shell.execute_reply":"2022-03-11T07:53:56.746444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding for tree-based models\ndef label_encode_manual(df):\n    '''tested: passing'''\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] =  X[colname].cat.codes\n        \n    return X\n\n# label encoding using sklearn module LabelEncoder\ndef label_encode_sk(df):\n    '''tested: passing'''\n    X = df.copy()\n    categorical_columns = X.select_dtypes([\"category\"]).columns\n    \n    le = LabelEncoder()\n    X[categorical_columns] = X[categorical_columns].apply(lambda x: le.fit_transform(x))\n    return X\n\n# One Hot encoding for linear regression based models, and svm\ndef one_hot_encode_pd(df):\n    '''tested: passing'''\n    X = df.copy()\n    # for now we just use all categorical variables\n    cols_for_one_hot = X.select_dtypes([\"category\"])\n        \n    X = pd.get_dummies(X, columns=cols_for_one_hot, prefix=str(cols_for_one_hot + \"_\"))\n    return X\n        \ndef one_hot_encode_sk(df):\n    '''tested: passing'''\n    X = df.copy()\n    cols_for_one_hot = X.select_dtypes([\"category\"]).columns\n    \n    ohe = OneHotEncoder()\n    X[cols_for_one_hot] = X[cols_for_one_hot].apply(lambda x: ohe.fit_transform(x))\n    \n    return X\n\ndef oh_encode_hosues2(df):\n    pass\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.749163Z","iopub.execute_input":"2022-03-11T07:53:56.749696Z","iopub.status.idle":"2022-03-11T07:53:56.768564Z","shell.execute_reply.started":"2022-03-11T07:53:56.749626Z","shell.execute_reply":"2022-03-11T07:53:56.767872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_outliers(df):\n    outlier_mask = df['Outlier'] == 0\n    df = df.loc[outlier_mask]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.769751Z","iopub.execute_input":"2022-03-11T07:53:56.770004Z","iopub.status.idle":"2022-03-11T07:53:56.78305Z","shell.execute_reply.started":"2022-03-11T07:53:56.769958Z","shell.execute_reply":"2022-03-11T07:53:56.779568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features_01(df, test_set=None, normalize=False, out_format='tree'):\n    X = df.copy()\n    y = X.pop(\"SalePrice\")\n    mi_scores = make_mi_scores(X, y)\n    \n    # combine data if necessary\n    if test_set is not None:\n        X_test = test_set.copy()\n        X_test.pop(\"SalePrice\")\n        X = pd.concat([X, X_test])\n        \n    # Mutual Information\n    X = drop_uninformative(X, mi_scores)\n    \n    # Transformations\n    X = X.join(mathematical_transforms(X))\n    X = X.join(interactions(X))\n    X = X.join(porch_counts(X))\n    #X = X.join(class_break_down(X))\n    X = X.join(group_transforms(X))\n    \n    # Clustering\n    X = X.join(cluster_labels(X, cluster_features, n_clusters=20))\n    X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n    \n    # Principal Component Analysis\n    X = X.join(pca_driven_features(X))\n    X = X.join(pca_components(X, get_pca_feature_names()))\n    \n    X = X.join(indicate_outliers(X))\n    \n    X = label_encode_manual(X)\n    \n    # re-split data\n    if test_set is not None:\n        X_test = X.loc[test_set.index, :]\n        X.drop(test_set.index, inplace=True)\n        \n    # Target Encoder options\n    #encoder_me = CrossFoldEncoder(MEstimateEncoder, m=1)\n    encoder_cbe = CrossFoldEncoder(CatBoostEncoder, a=2)\n    \n    X = X.join(encoder_cbe.fit_transform(X, y, cols=[\"MSSubClass\"]))\n    \n        # Handle Optional Normalization\n    if normalize: \n#         X = normalize_numerics(X)\n        X = de_skew_yeo(X)\n    \n    # Handle Optional Test Set\n    if test_set is not None: \n        X_test = X_test.join(encoder_cbe.transform(X_test))\n    \n    if test_set is not None:\n        return X, X_test\n    else:\n        return X ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.788218Z","iopub.execute_input":"2022-03-11T07:53:56.788518Z","iopub.status.idle":"2022-03-11T07:53:56.805856Z","shell.execute_reply.started":"2022-03-11T07:53:56.788486Z","shell.execute_reply":"2022-03-11T07:53:56.804854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features_02(df, test_set=None, normalize=False, targ=True):\n    X = df.copy()\n    if targ:\n        y = X.pop(\"SalePrice\")\n    mi_scores = make_mi_scores(X, y)\n    \n    # combine data if necessary\n    if test_set is not None:\n        X_test = test_set.copy()\n        X_test.pop(\"SalePrice\")\n        X = pd.concat([X, X_test])\n        \n    # Mutual Information\n    X = drop_uninformative(X, mi_scores)\n    \n    # Transformations1\n    X = X.join(mathematical_transforms(X))\n    X = X.join(interactions(X))\n    X = X.join(porch_counts(X))\n    #X = X.join(class_break_down(X))\n    X = X.join(group_transforms(X))\n    \n    # Transformations2\n    \n    # Clustering\n    X = X.join(cluster_labels(X, cluster_features, n_clusters=20))\n    X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n    \n    # Principal Component Analysis\n    X = X.join(pca_driven_features(X))\n    X = X.join(pca_components(X, get_pca_feature_names()))\n    \n    # remove outliers handled prior to input\n    #X = X.join(indicate_outliers(X))\n    #X = remove_outliers(X) \n    \n    # Handle Optional Normalization\n    if normalize: \n        X = de_skew_yeo(X)\n        \n    # numerical encoding for categorical variables\n    X = label_encode_manual(X)\n    \n    # re-split data\n    if test_set is not None:\n        X_test = X.loc[test_set.index, :]\n        X.drop(test_set.index, inplace=True)\n        \n    # Target Encoder options\n    #encoder_me = CrossFoldEncoder(MEstimateEncoder, m=1)\n    encoder_cbe = CrossFoldEncoder(CatBoostEncoder, a=2)\n    \n    X = X.join(encoder_cbe.fit_transform(X, y, cols=[\"MSSubClass\"]))\n    \n    # Handle Optional Test Set\n    if test_set is not None: \n        X_test = X_test.join(encoder_cbe.transform(X_test))\n    \n    if test_set is not None:\n        return X, X_test\n    else:\n        return X ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.807334Z","iopub.execute_input":"2022-03-11T07:53:56.807855Z","iopub.status.idle":"2022-03-11T07:53:56.824828Z","shell.execute_reply.started":"2022-03-11T07:53:56.807806Z","shell.execute_reply":"2022-03-11T07:53:56.82385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import missingno as msno\ndef check_missing(X_train):\n    df_miss = X_train.isna().sum().sort_values(ascending=False)\n\n    cols_w_miss = df_miss[df_miss > 0].index\n    print(X_train[cols_w_miss].info())","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:53:56.826183Z","iopub.execute_input":"2022-03-11T07:53:56.82641Z","iopub.status.idle":"2022-03-11T07:53:56.843111Z","shell.execute_reply.started":"2022-03-11T07:53:56.826383Z","shell.execute_reply":"2022-03-11T07:53:56.841572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_stacked_data(vers=1):\n    # --------------------\n    if vers == 1:\n        print(\"loading data...\")\n        df_train, df_test = load_and_preproc_data()\n        y_train = np.log(df_train[\"SalePrice\"])\n        df_train.drop(['Street'], axis=1)\n        \n        print(\"Engineering Features...\")\n        X_train, X_test = create_features_01(df_train, test_set=df_test, normalize= False)\n        \n        # remove outlier observations \n        X_train = X_train.loc[X_train['Outlier']==0]\n        y_train =  y_train.loc[X_train.index]\n        # remove outlier indicator column\n        X_train = X_train.drop(['Outlier'], axis='columns')\n        X_test = X_test.drop(['Outlier'], axis='columns')\n        print(\"complete\")\n        return X_train, X_test, y_train, \n        \n    if vers == 2:\n        print(\"loading data...\")\n        df_train, df_test = load_and_preproc_data()\n        y_train = np.log(df_train[\"SalePrice\"])\n        df_train.drop(['Street'], axis=1)\n        \n        df_train = df_train.join(indicate_outliers(df_train))\n        df_train = remove_outliers(df_train)\n        y_train = y_train.loc[df_train.index]\n        \n        print(\"Engineering Features...\")\n        X_train, X_test = create_features_02(df_train, test_set=df_test, normalize=True)\n        \n        print(\"complete\")\n        return X_train, X_test, y_train\n    \n    if vers == 3:\n        df_train, df_test, df_train_y, df_test_y = load_and_preproc_data(type='tt_split')\n\n        df_train = df_train.join(indicate_outliers(df_train))\n        df_train = remove_outliers(df_train)\n        df_train_y = df_train_y.loc[df_train.index]\n        \n        df_train = df_train.join(df_train_y)\n        df_test = df_test.join(df_test_y)\n        \n        print(\"Engineering Features...\")\n        X_train, X_test = create_features_02(df_train, test_set=df_test, normalize=True)\n        \n        y_train = np.log(df_train_y)\n        y_test = np.log(df_test_y)\n        \n        print(\"complete\")\n        return X_train, X_test, y_train, y_test\n\n        # active","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:09:59.934058Z","iopub.execute_input":"2022-03-11T08:09:59.934649Z","iopub.status.idle":"2022-03-11T08:09:59.950223Z","shell.execute_reply.started":"2022-03-11T08:09:59.934586Z","shell.execute_reply":"2022-03-11T08:09:59.949041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train_2, X_test_2, y_train_2, y_test_2 = prepare_stacked_data(vers=2)\nX_n3, X_t3, y_n3, y_t3 = prepare_stacked_data(vers=3)\n\ndata_ref3 = [X_n3, X_t3, y_n3, y_t3]\ndef refresh_data():\n    return data_ref3[0], data_ref3[1], data_ref3[2], data_ref3[3]","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:17:56.989065Z","iopub.execute_input":"2022-03-11T08:17:56.989466Z","iopub.status.idle":"2022-03-11T08:18:56.171499Z","shell.execute_reply.started":"2022-03-11T08:17:56.989424Z","shell.execute_reply":"2022-03-11T08:18:56.170597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_2, X_test_2, y_train_2 = prepare_stacked_data(vers=2)\nX_n2, X_t2, y_n2, y_t2 = train_test_split(X_train_2, y_train_2, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:03:55.100444Z","iopub.execute_input":"2022-03-11T08:03:55.10074Z","iopub.status.idle":"2022-03-11T08:05:16.655944Z","shell.execute_reply.started":"2022-03-11T08:03:55.10071Z","shell.execute_reply":"2022-03-11T08:05:16.655113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train, df_test = load_and_preproc_data()\n# skew_cutoff=0.5\n# X = df_train.copy()\n# numeric_columns = X.select_dtypes([\"number\"]).columns\n# skew_feats = X[numeric_columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n\n# too_skew = skew_feats[skew_feats > skew_cutoff].index\n\n\n# # normalize each of the features with high skew with scipy boxcox \n#for s in too_skew:\n#    X[s] = boxcox1p(X[s], boxcox_normmax(X[s] + 1))\n# return X","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.629142Z","iopub.execute_input":"2022-03-11T07:54:54.629627Z","iopub.status.idle":"2022-03-11T07:54:54.643636Z","shell.execute_reply.started":"2022-03-11T07:54:54.629581Z","shell.execute_reply":"2022-03-11T07:54:54.64279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# test_col = 'PoolArea'\n# # test_col = KitchenAbvGr \t\n\n# X[test_col].dropna()\n# print(f\"pre cox: {X[test_col].skew()}\")\n# X[test_col] = np.log(X[test_col])\n# # X[test_col] = boxcox(X[test_col], boxcox_normmax(X[test_col]))\n# print(f\" post cox: {X[test_col].skew()}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.64509Z","iopub.execute_input":"2022-03-11T07:54:54.645484Z","iopub.status.idle":"2022-03-11T07:54:54.648865Z","shell.execute_reply.started":"2022-03-11T07:54:54.64545Z","shell.execute_reply":"2022-03-11T07:54:54.648154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train, df_test = load_and_preproc_data()\n\n# skews = find_skew_cols(X_train_2)\n# skews_o = find_skew_cols(df_train)\n\n# test_skew_cols = [ col for col in skews_o.index.tolist() if col in skews.index.tolist()]\n# pd.DataFrame([skews[test_skew_cols], skews_o[test_skew_cols]])['GrLivArea']\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.650065Z","iopub.execute_input":"2022-03-11T07:54:54.6506Z","iopub.status.idle":"2022-03-11T07:54:54.661543Z","shell.execute_reply.started":"2022-03-11T07:54:54.650557Z","shell.execute_reply":"2022-03-11T07:54:54.660816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# size_mask = X_train['GrLivArea'] > 4000\n# cond_mask  = X_train.SaleCondition == \"Partial\"\n# X_train.loc[cond_mask][\"Outlier\"]\n# X_train[\"SaleCondition\"].cat.codes","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.662829Z","iopub.execute_input":"2022-03-11T07:54:54.663232Z","iopub.status.idle":"2022-03-11T07:54:54.672424Z","shell.execute_reply.started":"2022-03-11T07:54:54.663195Z","shell.execute_reply":"2022-03-11T07:54:54.671588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------\n# to delete - preserve for reference somewhere\n# ---------------\n\ndef experiment_data_conversion():\n    # save the datatypes\n    in_dtypes = pd.DataFrame(X_train.dtypes)\n    in_dtypes.reset_index(inplace=True)\n    in_dtypes.columns = ['col', 'type']\n    in_dtypes.to_csv('/kaggle/working/input_dtypes.csv', index=False)\n\n    # Read back the data types\n    input_types = pd.read_csv('/kaggle/working/input_dtypes.csv')\n    input_dtypes = dict(zip(input_types.col, input_types.type))\n    # other option\n    # input_types.set_index('col').to_dict()['type']\n    input_dtypes","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.673514Z","iopub.execute_input":"2022-03-11T07:54:54.674056Z","iopub.status.idle":"2022-03-11T07:54:54.684898Z","shell.execute_reply.started":"2022-03-11T07:54:54.674017Z","shell.execute_reply":"2022-03-11T07:54:54.684004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wtf is going on here \nfrom sklearn.impute import SimpleImputer\n\ndef test_target_imputer():\n    test_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n    X_t_impute = test_imputer.fit_transform(X_test)\n\n    return check_missing(X_t_impute)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.686289Z","iopub.execute_input":"2022-03-11T07:54:54.686606Z","iopub.status.idle":"2022-03-11T07:54:54.700423Z","shell.execute_reply.started":"2022-03-11T07:54:54.686572Z","shell.execute_reply":"2022-03-11T07:54:54.699469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n---\n---\n---\n# Chapter 2: Model Training\n---\n---\n---\n---","metadata":{}},{"cell_type":"code","source":"# Define error metrics\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef cv_rmse(model, X, y, kf):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n    return (rmse)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.701393Z","iopub.execute_input":"2022-03-11T07:54:54.702093Z","iopub.status.idle":"2022-03-11T07:54:54.715094Z","shell.execute_reply.started":"2022-03-11T07:54:54.702033Z","shell.execute_reply":"2022-03-11T07:54:54.714125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stacked_scores(stk_model, X_dat, y_dat, method='orig'):\n    stacked_models = [name for name in stk_model.named_estimators_.keys()]\n    \n    if method is 'orig':\n        stacked_scores = [model.score(X_dat,y_dat) for model in stk_model.named_estimators_.values()]\n        stk_scores = list(zip(stacked_models, stacked_scores))\n        stk_scores.insert(0, (\"stacked model\", stk_model.score(X_dat, y_dat)))\n    \n    elif method is 'rmsle':\n        stacked_scores = [score_dataset(X_dat,y_dat, model=model, enc=False, trans_targ=False) for model in stk_model.named_estimators_.values()]\n        stk_scores = list(zip(stacked_models, stacked_scores))\n        stack_rmsle = score_dataset(X_dat, y_dat, model=stk_model, enc=False, trans_targ=False)\n        stk_scores.insert(0, (\"stacked model\", stack_rmsle))\n    \n    else:\n        raise ValueError\n    \n    #print(stk_scores)\n    return stk_scores","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.716921Z","iopub.execute_input":"2022-03-11T07:54:54.717268Z","iopub.status.idle":"2022-03-11T07:54:54.735523Z","shell.execute_reply.started":"2022-03-11T07:54:54.717233Z","shell.execute_reply":"2022-03-11T07:54:54.734794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------------------------------- #\n# ------------------------------- # \n#     Stacked Model Section       #\n\n#-------------------------------\n# Preprocessing for stacked model\nfrom sklearn.compose import make_column_transformer, make_column_selector\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\n# Definining Cateogry Selectors\nnum_selector = make_column_selector(dtype_include=np.number)\ncat_selector  = make_column_selector(dtype_include='object') #possibly change to 'object' if not using encode() utilit function\n\n# tree preprocessor \ncat_tree_preprocessor = OrdinalEncoder()\n\n#num_tree_preprocessor = SimpleImputer(strategy=\"mean\", add_indicator=True)\n\ntree_preprocessor = make_column_transformer(\n     (cat_tree_preprocessor, cat_selector), #,(num_tree_preprocessor, num_selector) #todo: remove this imputation step handled in preprocess_data()\n    remainder = 'passthrough'\n    )","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.73651Z","iopub.execute_input":"2022-03-11T07:54:54.737027Z","iopub.status.idle":"2022-03-11T07:54:54.753752Z","shell.execute_reply.started":"2022-03-11T07:54:54.736979Z","shell.execute_reply":"2022-03-11T07:54:54.752758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear_preprocessor.fit_transform(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.755416Z","iopub.execute_input":"2022-03-11T07:54:54.75578Z","iopub.status.idle":"2022-03-11T07:54:54.764663Z","shell.execute_reply.started":"2022-03-11T07:54:54.755745Z","shell.execute_reply":"2022-03-11T07:54:54.763744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# linear preprocessor \ncat_linear_selector = features_nom\ncat_linear_preprocessor = OneHotEncoder(handle_unknown='ignore')\nnum_linear_preprocessor = make_pipeline(StandardScaler()) #,SimpleImputer(strategy='mean', add_indicator=True) \n                                                            #todo: this imputation step is handled in preprocess_data() -> simple_impute()                                     \nlinear_preprocessor = make_column_transformer(\n                                            (num_linear_preprocessor, num_selector), \n                                            (cat_linear_preprocessor, cat_linear_selector) \n                                            )","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:11:55.27276Z","iopub.execute_input":"2022-03-11T08:11:55.273048Z","iopub.status.idle":"2022-03-11T08:11:55.279053Z","shell.execute_reply.started":"2022-03-11T08:11:55.273018Z","shell.execute_reply":"2022-03-11T08:11:55.278129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# todo  \n# -------------------------\n# partial dependence plots\n\n# XX - optuna for stacked tree models\n    #_histgb wouldn't work with optuna for some reason\n\n\n# Shapley Value Analysis for Stacked Tree Models\n# -- XG Boost Question\n\n# Blended Model Version of Stacked Tree \n\n# Linear Models \n# remove colinearity for linear models \n# apply additional layer of simple math feature engineerings\n\n# -----------------\n# Case Studies\n# - remodel old house add value \n\n# At fixed Price, Most valuable features\n\n# Todo Complete\n# XX - Remove Outliers ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.780609Z","iopub.execute_input":"2022-03-11T07:54:54.781568Z","iopub.status.idle":"2022-03-11T07:54:54.793062Z","shell.execute_reply.started":"2022-03-11T07:54:54.781525Z","shell.execute_reply":"2022-03-11T07:54:54.792331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgbst_pipeline = make_pipeline(\n    tree_preprocessor, xgboost_stk\n)\n\nhistgb_pipeline = make_pipeline(\n    tree_preprocessor, HistGradientBoostingRegressor(random_state=0)\n)\n\nrf_pipeline = make_pipeline(\n    tree_preprocessor, RandomForestRegressor(random_state=2)\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:59:34.928038Z","iopub.execute_input":"2022-03-11T07:59:34.928897Z","iopub.status.idle":"2022-03-11T07:59:34.933791Z","shell.execute_reply.started":"2022-03-11T07:59:34.928844Z","shell.execute_reply":"2022-03-11T07:59:34.933107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------------\n# Linear Models\nlasso_pipeline = make_pipeline(\n    linear_preprocessor, LassoCV()\n)\n\nridge_pipeline = make_pipeline(\n    linear_preprocessor, RidgeCV()\n)\n\nsvr_pipeline = Pipeline([\n    ('prep',linear_preprocessor), \n    ('svr', SVR())\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T07:54:54.811082Z","iopub.execute_input":"2022-03-11T07:54:54.811311Z","iopub.status.idle":"2022-03-11T07:54:54.822447Z","shell.execute_reply.started":"2022-03-11T07:54:54.811281Z","shell.execute_reply":"2022-03-11T07:54:54.821494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_nn = X_n3\nX_tt = X_t3\ny_nn = y_n3\ny_tt = y_t3\n\nlasso_pipeline.fit(X_nn, y_nn)\nprint(rmsle(y_nn, lasso_pipeline.predict(X_nn)))\n\nls_preds = lasso_pipeline.predict(X_tt)\nlasso_pipeline.score(X_tt, y_tt)\nrmsle(y_tt, ls_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:20:02.867896Z","iopub.execute_input":"2022-03-11T08:20:02.868199Z","iopub.status.idle":"2022-03-11T08:20:03.012713Z","shell.execute_reply.started":"2022-03-11T08:20:02.868169Z","shell.execute_reply":"2022-03-11T08:20:03.011208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nridge_pipeline.fit(X_n2, y_n2)\nprint(rmsle(y_n2, ridge_pipeline.predict(X_n2)))\n\nrdg_preds = ridge_pipeline.predict(X_t2)\nridge_pipeline.score(X_t2, y_t2)\nrmsle(y_t2, rdg_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T08:12:14.106157Z","iopub.execute_input":"2022-03-11T08:12:14.106818Z","iopub.status.idle":"2022-03-11T08:12:14.215715Z","shell.execute_reply.started":"2022-03-11T08:12:14.106781Z","shell.execute_reply":"2022-03-11T08:12:14.213744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_n2, X_t2, y_n2, y_t2 = train_test_split(X_train_2, y_train_2, test_size=0.2, random_state=42)\n\n# sv_params = {'svr__C' :[1,5,10],\n#                  'svr__degree': [1,2,3,5,8],\n#                  'svr__coef0': [0.01, 0.5, 10],\n#                  'svr__gamma': ('auto', scale)\n#             }\n\ndef run_gsearch_sv():\n    sv_params={\n                'svr__C': [0.1, 1, 100, 1000],\n                'svr__epsilon': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n                'svr__gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n                },\n\n    sv_grids = GridSearchCV(svr_pipeline, sv_params, cv=5, scoring='neg_mean_squared_error')\n    sv_grids.fit(X_n2, y_n2)\n\n    svr_pipeline_b = sv_grids.best_estimator_\n\n    svr_pipeline_b.fit(X_n2, y_n2)\n    svr_preds = svr_pipeline_b.predict(X_t2)\n    svr_pipeline_b.score(X_t2, y_t2)\n    print(rmsle(y_t2, svr_preds))\n    return svr_pipeline_b\n    \nsv_results = run_gsearch_sv()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T01:34:46.160894Z","iopub.execute_input":"2022-03-11T01:34:46.161225Z","iopub.status.idle":"2022-03-11T01:46:48.691642Z","shell.execute_reply.started":"2022-03-11T01:34:46.16119Z","shell.execute_reply":"2022-03-11T01:46:48.690471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_n2, X_t2, y_n2, y_t2 = train_test_split(X_train_2, y_train_2, test_size=0.2, random_state=42)\n\nsv_results.fit(X_n2, y_n2)\nprint(rmsle(y_n2, sv_results.predict(X_n2)))\n\nsv_preds = sv_results.predict(X_t2)\nsv_results.score(X_t2, y_t2)\nrmsle(y_t2, sv_preds)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:03:46.684125Z","iopub.execute_input":"2022-03-11T02:03:46.684829Z","iopub.status.idle":"2022-03-11T02:03:48.699982Z","shell.execute_reply.started":"2022-03-11T02:03:46.684785Z","shell.execute_reply":"2022-03-11T02:03:48.69913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle(y_n2, svr_pipeline_b.predict(X_n2))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:37:39.463618Z","iopub.execute_input":"2022-03-10T23:37:39.464383Z","iopub.status.idle":"2022-03-10T23:37:40.008667Z","shell.execute_reply.started":"2022-03-10T23:37:39.464335Z","shell.execute_reply":"2022-03-10T23:37:40.007922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lin_prep_pipeline = Pipeline([('prep', linear_preprocessor)])","metadata":{"execution":{"iopub.status.busy":"2022-03-11T01:18:47.556509Z","iopub.execute_input":"2022-03-11T01:18:47.556983Z","iopub.status.idle":"2022-03-11T01:18:47.652525Z","shell.execute_reply.started":"2022-03-11T01:18:47.55689Z","shell.execute_reply":"2022-03-11T01:18:47.651368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_dat = pd.Concat(preds, y_t2)\nlassoo_dat","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_force(20, lasso_pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:34:26.913301Z","iopub.execute_input":"2022-03-10T20:34:26.91363Z","iopub.status.idle":"2022-03-10T20:34:26.974292Z","shell.execute_reply.started":"2022-03-10T20:34:26.913593Z","shell.execute_reply":"2022-03-10T20:34:26.973185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:43:19.609389Z","iopub.execute_input":"2022-03-09T02:43:19.609654Z","iopub.status.idle":"2022-03-09T02:43:19.626087Z","shell.execute_reply.started":"2022-03-09T02:43:19.609623Z","shell.execute_reply":"2022-03-09T02:43:19.625081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_seed = 2","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:04:52.738251Z","iopub.execute_input":"2022-03-11T02:04:52.738672Z","iopub.status.idle":"2022-03-11T02:04:52.742141Z","shell.execute_reply.started":"2022-03-11T02:04:52.738641Z","shell.execute_reply":"2022-03-11T02:04:52.741389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = create_features(df_train)\n# y_train = df_train.loc[:, \"SalePrice\"]\n\ndef run_xgb_optuna():\n    \n    def objective(trial):\n        xgb_params = dict(\n            max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n            learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n            n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n            min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n            subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n            reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n            reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n        )\n        xgb = XGBRegressor(**xgb_params, random_state=rand_seed)\n        return score_dataset(X_train, y_train, xgb, enc=False, trans_targ=False)\n    \n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=10)\n    \n    return study.best_params\n\n# xgb_param_stk = run_xgb_optuna()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:31:13.323544Z","iopub.execute_input":"2022-03-08T22:31:13.32428Z","iopub.status.idle":"2022-03-08T22:31:13.33201Z","shell.execute_reply.started":"2022-03-08T22:31:13.324242Z","shell.execute_reply":"2022-03-08T22:31:13.331104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params_opt = {\n    'max_depth': 4,\n     'learning_rate': 0.05354363798458815,\n     'n_estimators': 5156,\n     'min_child_weight': 6,\n     'colsample_bytree': 0.334883002631706,\n     'subsample': 0.9095426160373565,\n     'reg_alpha': 0.009835234945007399,\n     'reg_lambda': 0.017678554214634153}","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:04:56.928823Z","iopub.execute_input":"2022-03-11T02:04:56.929133Z","iopub.status.idle":"2022-03-11T02:04:56.934491Z","shell.execute_reply.started":"2022-03-11T02:04:56.929097Z","shell.execute_reply":"2022-03-11T02:04:56.933446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_histgb_optuna():\n    \n    # creating index mask for categorical features argument\n    # creating index mask for categorical features argument\n    # would I need to check the engineered features as well? \n    updt_cat_feats = [feat  for feat in features_cat if feat in X_train.columns]\n    cat_feature_indxs = [X_train.columns.get_loc(feat) for feat in updt_cat_feats]\n\n    def objective(trial):\n        histgb_params = dict(\n            learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e2, log=True),\n            max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\",1,50),\n            # max_depth = trial.suggest_int( default=None),\n            # max_iter = trial.suggest_int(\"max_iter\", defualt=100),\n            min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 10, 30), # default=20; \n            l2_regularization = trial.suggest_float(\"l2_regularization\",1e-4,1e2,log=True),\n            max_bins = trial.suggest_float(\"max_bins\",100,255), #max bins for non-missing values, must be no larger than 255\n            #categorical_features = cat_feature_indxs # new in version 0.24\n        )\n        \n        hgb = HistGradientBoostingRegressor(**histgb_params, random_state=rand_seed)\n        return score_dataset(X_train, y_train, hgb, enc=False, trans_targ=False)\n    \n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=10)\n    \n    return study.best_parameters\n\n# histgb_param_stk = run_histgb_optuna()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:31:14.478857Z","iopub.execute_input":"2022-03-08T22:31:14.479343Z","iopub.status.idle":"2022-03-08T22:31:14.487284Z","shell.execute_reply.started":"2022-03-08T22:31:14.479301Z","shell.execute_reply":"2022-03-08T22:31:14.486798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_rf_optuna():\n    \n    def objective(trial):\n\n        rf_params = dict(\n            n_estimators = trial.suggest_int(\"n_estimators\", 50, 200),\n            #max_depth defaul=None\n            min_samples_split = trial.suggest_int(\"min_samples_split\", 2,6), # default = 2\n            min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10), # defualt = 1\n            #min_weight_fraction_leaf : float; default = 0.0\n            #max_features = # default = 'auto'\n            #max_leaf_nodes = # default = None\n            #min_impurity_decrease # float, defualt= 0.0\n        )\n\n        rf = RandomForestRegressor(**rf_params, random_state=rand_seed)\n        return score_dataset(X_train, y_train, rf, enc=False, trans_targ=False)\n\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=10)\n\n    return study.best_params\n\n# rf_param_stk = run_rf_optuna()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:31:15.15265Z","iopub.execute_input":"2022-03-08T22:31:15.153141Z","iopub.status.idle":"2022-03-08T22:31:15.158958Z","shell.execute_reply.started":"2022-03-08T22:31:15.153106Z","shell.execute_reply":"2022-03-08T22:31:15.158465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_params_opt = {'n_estimators': 132, 'min_samples_split': 4, 'min_samples_leaf': 2}","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:05:02.175713Z","iopub.execute_input":"2022-03-11T02:05:02.176674Z","iopub.status.idle":"2022-03-11T02:05:02.181257Z","shell.execute_reply.started":"2022-03-11T02:05:02.176634Z","shell.execute_reply":"2022-03-11T02:05:02.179999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_seed = 2\n\nxgb_params_opt = {\n    'max_depth': 4,\n     'learning_rate': 0.05354363798458815,\n     'n_estimators': 5156,\n     'min_child_weight': 6,\n     'colsample_bytree': 0.334883002631706,\n     'subsample': 0.9095426160373565,\n     'reg_alpha': 0.009835234945007399,\n     'reg_lambda': 0.017678554214634153}\n\nrf_params_opt = {'n_estimators': 132, 'min_samples_split': 4, 'min_samples_leaf': 2}\n\n# make Stacked Model\ndef train_stacked_model_tree():\n    # --------------------\n    stack_estimators = {\n        (\"XGBoost\", XGBRegressor(**xgb_params_opt, random_state=rand_seed)),\n        #(\"HistGB\", HistGradientBoostingRegressor(random_state=rand_seed)),\n        #(\"Random Forest\", RandomForestRegressor(**rf_params_opt, random_state=rand_seed)),  \n        (\"lasso\", lasso_pipeline),\n        (\"ridge\", ridge_pipeline),\n        (\"svr\", sv_results)\n    }\n\n    #final_reg = XGBRegressor(random_state=2)\n    final_reg = RidgeCV()\n\n    print('Creating Initial Model...')\n    stacked_model = StackingRegressor(estimators=stack_estimators, final_estimator=final_reg)\n    print('Training Underway...')\n    stacked_model.fit(X_n2, y_n2)\n    print(rmsle(y_t2, stacked_model.predict(X_t2)))\n    return stacked_model\n\n#    End Stacked Model Section    #\n# ------------------------------- #\n# ------------------------------- # ","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:08:27.701826Z","iopub.execute_input":"2022-03-11T02:08:27.70216Z","iopub.status.idle":"2022-03-11T02:08:27.711549Z","shell.execute_reply.started":"2022-03-11T02:08:27.702126Z","shell.execute_reply":"2022-03-11T02:08:27.710681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_stack_model_tree = train_stacked_model_tree()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:08:36.087485Z","iopub.execute_input":"2022-03-11T02:08:36.087989Z","iopub.status.idle":"2022-03-11T02:10:41.433583Z","shell.execute_reply.started":"2022-03-11T02:08:36.087951Z","shell.execute_reply":"2022-03-11T02:10:41.431404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle(y_t2, final_stack_model_tree.predict(X_t2))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:11:24.908228Z","iopub.execute_input":"2022-03-11T02:11:24.908575Z","iopub.status.idle":"2022-03-11T02:11:25.125198Z","shell.execute_reply.started":"2022-03-11T02:11:24.90854Z","shell.execute_reply":"2022-03-11T02:11:25.124343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_stacked_scores(final_stack_model_tree, X_train, y_train, method='rmsle')","metadata":{"execution":{"iopub.status.busy":"2022-03-10T22:42:44.722714Z","iopub.execute_input":"2022-03-10T22:42:44.723062Z","iopub.status.idle":"2022-03-10T22:42:44.76086Z","shell.execute_reply.started":"2022-03-10T22:42:44.723028Z","shell.execute_reply":"2022-03-10T22:42:44.759607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score_dataset(X_train, y_train, model=rf_sub_est ,enc=False, trans_targ=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:31:18.53625Z","iopub.execute_input":"2022-03-08T22:31:18.536921Z","iopub.status.idle":"2022-03-08T22:31:18.540601Z","shell.execute_reply.started":"2022-03-08T22:31:18.536872Z","shell.execute_reply":"2022-03-08T22:31:18.539595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_n, X_t, y_n, y_t = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:44:04.00909Z","iopub.execute_input":"2022-03-09T02:44:04.009921Z","iopub.status.idle":"2022-03-09T02:44:04.01552Z","shell.execute_reply.started":"2022-03-09T02:44:04.009868Z","shell.execute_reply":"2022-03-09T02:44:04.014993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=0, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:44:09.064628Z","iopub.execute_input":"2022-03-09T02:44:09.065082Z","iopub.status.idle":"2022-03-09T02:44:09.068803Z","shell.execute_reply.started":"2022-03-09T02:44:09.065035Z","shell.execute_reply":"2022-03-09T02:44:09.068069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_bl = RandomForestRegressor(**rf_params_opt, random_state=rand_seed)\n# ----------------\n#rf_bl.fit(X_train, y_train)\n# print(score_dataset(X_train, y_train, rf_bl, enc=False, trans_targ=False))\n# ----------------\n# rf_bl.fit(X_n, y_n)\n# print(rf_bl.score(X_t, y_t))\n# print(rmsle(y_t, rf_bl.predict(X_t)))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:05:23.310621Z","iopub.execute_input":"2022-03-11T02:05:23.310927Z","iopub.status.idle":"2022-03-11T02:05:23.315801Z","shell.execute_reply.started":"2022-03-11T02:05:23.310891Z","shell.execute_reply":"2022-03-11T02:05:23.314879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_bl_preds = rf_bl.predict(X_train).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T23:01:53.073341Z","iopub.execute_input":"2022-03-08T23:01:53.073645Z","iopub.status.idle":"2022-03-08T23:01:53.121501Z","shell.execute_reply.started":"2022-03-08T23:01:53.073613Z","shell.execute_reply":"2022-03-08T23:01:53.120805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_bl = XGBRegressor(**xgb_params_opt, random_state=rand_seed)\n# ----------------\n# xgb_bl.fit(X_train, y_train)\n# print(score_dataset(X_train, y_train, xgb_bl, enc=False, trans_targ=False))\n# ----------------\n# xgb_bl.fit(X_n, y_n)\n# print(xgb_bl.score(X_t, y_t))\n# print(rmsle(y_t, xgb_bl.predict(X_t)))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:05:25.287803Z","iopub.execute_input":"2022-03-11T02:05:25.288408Z","iopub.status.idle":"2022-03-11T02:05:25.293367Z","shell.execute_reply.started":"2022-03-11T02:05:25.288359Z","shell.execute_reply":"2022-03-11T02:05:25.292646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_bl_preds = xgb_bl.predict(X_train).tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T23:01:50.051734Z","iopub.execute_input":"2022-03-08T23:01:50.052009Z","iopub.status.idle":"2022-03-08T23:01:50.100829Z","shell.execute_reply.started":"2022-03-08T23:01:50.05198Z","shell.execute_reply":"2022-03-08T23:01:50.100177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hgb_bl = HistGradientBoostingRegressor(random_state=rand_seed)\n# ----------------\n# hgb_bl.fit(X_train, y_train)\n# print(score_dataset(X_train, y_train, hgb_bl, enc=False, trans_targ=False))\n# ----------------\nhgb_bl.fit(X_n, y_n)\nprint(hgb_bl.score(X_t, y_t))\nprint(rmsle(y_t, hgb_bl.predict(X_t)))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T02:51:52.610307Z","iopub.execute_input":"2022-03-09T02:51:52.610571Z","iopub.status.idle":"2022-03-09T02:51:54.141167Z","shell.execute_reply.started":"2022-03-09T02:51:52.610542Z","shell.execute_reply":"2022-03-09T02:51:54.140575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score_dataset(X_train, y_train, enc=False, trans_targ=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:31:47.547596Z","iopub.execute_input":"2022-03-08T22:31:47.548166Z","iopub.status.idle":"2022-03-08T22:31:47.553806Z","shell.execute_reply.started":"2022-03-08T22:31:47.548128Z","shell.execute_reply":"2022-03-08T22:31:47.553101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------------------------\n# Blended Model\n#------------------------\ndef train_blended_nt():\n    #X_n, X_t, y_n, y_t = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\n    models_dict = {'xgb': {'model': xgb_bl, 'weight': 0.7},\n                  #'rforest': {'model': rf_bl, 'weight': 0.3},\n                   'lasso_pip': {'model': lasso_pipeline, 'weight': 0.4},\n                   'ridge_pip': {'model': ridge_pipeline, 'weight': 0.2},\n                   'svr_pip': {'model': sv_results, 'weight': 0.4}\n                  #'hgb': {'model': hgb_bl, 'weight': 0.25}\n                  #'stacked': {'model': stacked_model, 'weight': 0.25}}\n                  }\n\n    reg_models = [(key, value['model']) for key, value in models_dict.items()]\n    vote_weights = [value['weight'] for value in models_dict.values()]\n\n    vote_reg = VotingRegressor(estimators=reg_models)\n    # --------------\n    # vote_reg.fit(X_train, y_train)\n    # print(score_dataset(X_train, y_train, vote_reg, enc=False, trans_targ=False))\n    \n    # --------------\n    vote_reg.fit(X_n2, y_n2)\n    print(rmsle(y_t2, vote_reg.predict(X_t2)))\n    return vote_reg\n\nvote_reg_p = train_blended_nt()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:06:32.357769Z","iopub.execute_input":"2022-03-11T02:06:32.358087Z","iopub.status.idle":"2022-03-11T02:06:55.782324Z","shell.execute_reply.started":"2022-03-11T02:06:32.358051Z","shell.execute_reply":"2022-03-11T02:06:55.78147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle(y_n2, vote_reg_p.predict(X_n2))","metadata":{"execution":{"iopub.status.busy":"2022-03-11T02:07:30.165446Z","iopub.execute_input":"2022-03-11T02:07:30.165728Z","iopub.status.idle":"2022-03-11T02:07:30.825673Z","shell.execute_reply.started":"2022-03-11T02:07:30.1657Z","shell.execute_reply":"2022-03-11T02:07:30.824799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_reg_p.named_estimators_['lasso_pip'].named_steps['lassocv'].get_params()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:15:17.51338Z","iopub.execute_input":"2022-03-10T21:15:17.513661Z","iopub.status.idle":"2022-03-10T21:15:17.521068Z","shell.execute_reply.started":"2022-03-10T21:15:17.513629Z","shell.execute_reply":"2022-03-10T21:15:17.519949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_reg_p.named_estimators_","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:50:03.29552Z","iopub.execute_input":"2022-03-10T20:50:03.295936Z","iopub.status.idle":"2022-03-10T20:50:03.333315Z","shell.execute_reply.started":"2022-03-10T20:50:03.295902Z","shell.execute_reply":"2022-03-10T20:50:03.332379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_reg_p.feature_importance_","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:49:19.504579Z","iopub.execute_input":"2022-03-10T20:49:19.507448Z","iopub.status.idle":"2022-03-10T20:49:19.564088Z","shell.execute_reply.started":"2022-03-10T20:49:19.507381Z","shell.execute_reply":"2022-03-10T20:49:19.561173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"___ \n___\nLinear Ensemble Models","metadata":{}},{"cell_type":"code","source":"# -----------------\n# Stacked Linear Model \n# ----------------\n\ndef train_linear_stacked_model():\n    stack_estimators_lm = [\n        #(\"lasso_stk\", lasso_pipeline),\n        (\"ridge_stk\", ridge_pipeline),\n        (\"svr_stk\", svr_pipeline)\n    ]\n    \n    final_reg_lm = RidgeCV()\n    \n    print('Creating Initial Model...')\n    stacked_model_lm = StackingRegressor(estimators=stack_estimators_lm, final_estimator=final_reg_lm)\n    print('Training Underway...')\n    stacked_model_lm.fit(X_train, y_train)\n    #stacked_model.score(X_test, Y_test)\n    print(\"training complete\")\n    return stacked_model_lm","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.593906Z","iopub.execute_input":"2022-03-06T01:27:57.594344Z","iopub.status.idle":"2022-03-06T01:27:57.604069Z","shell.execute_reply.started":"2022-03-06T01:27:57.594311Z","shell.execute_reply":"2022-03-06T01:27:57.603439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_stacked_linear_model = train_linear_stacked_model()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.607213Z","iopub.execute_input":"2022-03-06T01:27:57.60821Z","iopub.status.idle":"2022-03-06T01:27:57.614377Z","shell.execute_reply.started":"2022-03-06T01:27:57.60817Z","shell.execute_reply":"2022-03-06T01:27:57.613714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_stacked_linear_model.score(X_train, y_train)\n# get_stacked_scores(final_stacked_linear_model, X_train, y_train, method='rmsle')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.615733Z","iopub.execute_input":"2022-03-06T01:27:57.616193Z","iopub.status.idle":"2022-03-06T01:27:57.623303Z","shell.execute_reply.started":"2022-03-06T01:27:57.616156Z","shell.execute_reply":"2022-03-06T01:27:57.622664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score_dataset(X_train, y_train, model=final_stacked_linear_model, enc=False, trans_targ=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.624718Z","iopub.execute_input":"2022-03-06T01:27:57.625158Z","iopub.status.idle":"2022-03-06T01:27:57.633248Z","shell.execute_reply.started":"2022-03-06T01:27:57.625119Z","shell.execute_reply":"2022-03-06T01:27:57.632581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get_stacked_scores(final_stacked_linear_model, X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.634585Z","iopub.execute_input":"2022-03-06T01:27:57.635036Z","iopub.status.idle":"2022-03-06T01:27:57.641688Z","shell.execute_reply.started":"2022-03-06T01:27:57.635003Z","shell.execute_reply":"2022-03-06T01:27:57.641007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------\n# Combined Stacked Model \n# ----------------\n\ndef train_mixed_stacked_model():\n    \n    stack_estimators_mx = [\n        (\"ridge_stk\", svr_pipeline), \n        (\"XGBoost\", XGBRegressor(random_state=0)),\n        (\"HistGB\", HistGradientBoostingRegressor(random_state=0)),\n        (\"Random Forest\", RandomForestRegressor(random_state=2)), \n    ]\n\n    #final_reg_mx = RandomForestRegressor(random_state=0)\n    final_reg_mx = XGBRegressor(random_state=2)    \n    #final_reg_mx = RidgeCV()\n    \n    print('Creating Initial Model...')\n    stacked_model_mx = StackingRegressor(estimators=stack_estimators_mx, \n                                         final_estimator=final_reg_mx, \n                                        passthrough=True)\n    \n    print('Training Underway...')\n    stacked_model_mx.fit(X_train, y_train)\n    #stacked_model.score(X_test, Y_test)\n    print(\"training complete\")\n    return stacked_model_mx\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:39:53.129663Z","iopub.execute_input":"2022-03-06T01:39:53.130452Z","iopub.status.idle":"2022-03-06T01:39:53.137564Z","shell.execute_reply.started":"2022-03-06T01:39:53.130413Z","shell.execute_reply":"2022-03-06T01:39:53.136776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_mx_stacked_model = train_mixed_stacked_model()\nget_stacked_scores(final_mx_stacked_model, X_train, y_train, method='rmsle')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:39:55.005346Z","iopub.execute_input":"2022-03-06T01:39:55.005639Z","iopub.status.idle":"2022-03-06T01:39:55.075444Z","shell.execute_reply.started":"2022-03-06T01:39:55.005593Z","shell.execute_reply":"2022-03-06T01:39:55.073898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_mx_stacked_model.named_estimators_","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.896196Z","iopub.status.idle":"2022-03-06T01:27:57.898102Z","shell.execute_reply.started":"2022-03-06T01:27:57.897844Z","shell.execute_reply":"2022-03-06T01:27:57.897872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mx_stk_model = final_mx_stacked_model\n# histgb_pred = mx_stk_model.named_estimators_['HistGB'].predict(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.901487Z","iopub.status.idle":"2022-03-06T01:27:57.903395Z","shell.execute_reply.started":"2022-03-06T01:27:57.903156Z","shell.execute_reply":"2022-03-06T01:27:57.903182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hist_rval = np.exp(histgb_pred)\n# y_train_rval = np.exp(y_train)\n# hist_rval.shape\n# histgb_pred.shape\n# y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.906795Z","iopub.status.idle":"2022-03-06T01:27:57.908672Z","shell.execute_reply.started":"2022-03-06T01:27:57.908423Z","shell.execute_reply":"2022-03-06T01:27:57.90845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# comp_reals = pd.DataFrame(hist_rval, y_train_rval).reset_index()\n# comp_reals.columns = ['hist_rval', 'y_train_rval']\n# comp_reals['diff'] = comp_reals['hist_rval'] - comp_reals.y_train_rval\n# abs(comp_reals['diff']).max()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.911123Z","iopub.status.idle":"2022-03-06T01:27:57.91302Z","shell.execute_reply.started":"2022-03-06T01:27:57.912781Z","shell.execute_reply":"2022-03-06T01:27:57.912807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import seaborn as sns\n# sns.scatterplot(data=comp_reals, x=comp_reals.index, y='diff')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T01:27:57.914422Z","iopub.status.idle":"2022-03-06T01:27:57.918568Z","shell.execute_reply.started":"2022-03-06T01:27:57.918332Z","shell.execute_reply":"2022-03-06T01:27:57.918358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--- \n---\n# Blended Model Interpretability\n---\n---","metadata":{}},{"cell_type":"code","source":"# reference on getting explainer for a model\n\n# explainer = shap.TreeExplainer(my_model)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:16:21.431404Z","iopub.execute_input":"2022-03-07T21:16:21.431688Z","iopub.status.idle":"2022-03-07T21:16:21.435908Z","shell.execute_reply.started":"2022-03-07T21:16:21.43165Z","shell.execute_reply":"2022-03-07T21:16:21.435025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------\n# Investigate Shap Values for single prediction\n\ndef shap_force(row_to_show, explainer):\n    val_X = X_train\n    small_val_X = X_train.iloc[:150]\n    data_investigate = val_X.iloc[row_to_show]\n    \n    shap_values = explainer.shap_values(data_investigate)\n    # display shap value graphic\n    shap.initjs()\n    return shap.force_plot(explainer.expected_value, shap_values, data_investigate)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T22:56:50.92754Z","iopub.execute_input":"2022-03-10T22:56:50.927834Z","iopub.status.idle":"2022-03-10T22:56:50.932789Z","shell.execute_reply.started":"2022-03-10T22:56:50.927801Z","shell.execute_reply":"2022-03-10T22:56:50.932114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --------------------\ndef shap_summary(explainer):\n    val_X = X_train\n    small_val_X = X_train.iloc[:150]\n    shap_values = explainer.shap_values(val_X)\n    shap.summary_plot(shap_values, val_X)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T22:56:48.826669Z","iopub.execute_input":"2022-03-10T22:56:48.826999Z","iopub.status.idle":"2022-03-10T22:56:48.832095Z","shell.execute_reply.started":"2022-03-10T22:56:48.826964Z","shell.execute_reply":"2022-03-10T22:56:48.831483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_pdp_plot(my_model, feat_name, model_feats):\n    \"\"\"\n    model_feats : list \n    feat_name : str\n    \"\"\"\n    pdp_dist = pdp.pdp_isolate(model=my_model, dataset=X_train, model_features=model_feats, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:52:13.322557Z","iopub.execute_input":"2022-03-10T20:52:13.322901Z","iopub.status.idle":"2022-03-10T20:52:13.328549Z","shell.execute_reply.started":"2022-03-10T20:52:13.322862Z","shell.execute_reply":"2022-03-10T20:52:13.327788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gen_perm_import(my_model, feat_names):\n    \"\"\"\n    feat_names : list\n    \"\"\"\n    perm = PermutationImportance(my_model).fit(X_train, y_train)\n\n    # show the weights for the permutation importance \n    eli5.show_weights(perm, feature_names = feat_names)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:52:13.330195Z","iopub.execute_input":"2022-03-10T20:52:13.330542Z","iopub.status.idle":"2022-03-10T20:52:13.342672Z","shell.execute_reply.started":"2022-03-10T20:52:13.330512Z","shell.execute_reply":"2022-03-10T20:52:13.341649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_reg_perm = PermutationImportance(vote_reg_p).fit(X_n2, y_n2)\neli5.show_weights(vote_reg_perm, feature_names = X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:03:24.599167Z","iopub.execute_input":"2022-03-10T21:03:24.600139Z","iopub.status.idle":"2022-03-10T21:04:38.732655Z","shell.execute_reply.started":"2022-03-10T21:03:24.600084Z","shell.execute_reply":"2022-03-10T21:04:38.731538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vote_reg_perm","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:35:11.96547Z","iopub.execute_input":"2022-03-08T22:35:11.965977Z","iopub.status.idle":"2022-03-08T22:35:12.10391Z","shell.execute_reply.started":"2022-03-08T22:35:11.965933Z","shell.execute_reply":"2022-03-08T22:35:12.103043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'GarageArea', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:52:20.661356Z","iopub.execute_input":"2022-03-10T20:52:20.661777Z","iopub.status.idle":"2022-03-10T20:52:22.57193Z","shell.execute_reply.started":"2022-03-10T20:52:20.661746Z","shell.execute_reply":"2022-03-10T20:52:22.571034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'GarageCars', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:52:34.314312Z","iopub.execute_input":"2022-03-10T20:52:34.314876Z","iopub.status.idle":"2022-03-10T20:52:35.406186Z","shell.execute_reply.started":"2022-03-10T20:52:34.314816Z","shell.execute_reply":"2022-03-10T20:52:35.405208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what is spaciousness\ngen_pdp_plot(vote_reg_p, 'Spaciousness', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:52:53.161302Z","iopub.execute_input":"2022-03-10T20:52:53.161938Z","iopub.status.idle":"2022-03-10T20:52:54.898694Z","shell.execute_reply.started":"2022-03-10T20:52:53.161903Z","shell.execute_reply":"2022-03-10T20:52:54.897623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'YearRemodAdd', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:53:04.713888Z","iopub.execute_input":"2022-03-10T20:53:04.714177Z","iopub.status.idle":"2022-03-10T20:53:06.284262Z","shell.execute_reply.started":"2022-03-10T20:53:04.714147Z","shell.execute_reply":"2022-03-10T20:53:06.283303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'Feature1', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:53:25.674255Z","iopub.execute_input":"2022-03-10T20:53:25.674554Z","iopub.status.idle":"2022-03-10T20:53:27.366865Z","shell.execute_reply.started":"2022-03-10T20:53:25.674525Z","shell.execute_reply":"2022-03-10T20:53:27.365888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'Fireplaces', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:53:35.133908Z","iopub.execute_input":"2022-03-10T20:53:35.134207Z","iopub.status.idle":"2022-03-10T20:53:35.87485Z","shell.execute_reply.started":"2022-03-10T20:53:35.134172Z","shell.execute_reply":"2022-03-10T20:53:35.874015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'YearBuilt', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:53:49.791238Z","iopub.execute_input":"2022-03-10T20:53:49.792071Z","iopub.status.idle":"2022-03-10T20:53:51.985021Z","shell.execute_reply.started":"2022-03-10T20:53:49.792018Z","shell.execute_reply":"2022-03-10T20:53:51.984173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(hgb_bl, 'YearBuilt', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-08T00:43:51.443557Z","iopub.execute_input":"2022-03-08T00:43:51.443975Z","iopub.status.idle":"2022-03-08T00:43:51.856656Z","shell.execute_reply.started":"2022-03-08T00:43:51.443946Z","shell.execute_reply":"2022-03-08T00:43:51.854498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_pdp_plot(vote_reg_p, 'YearBuilt', X_train.columns.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:28.706511Z","iopub.execute_input":"2022-03-10T20:54:28.707067Z","iopub.status.idle":"2022-03-10T20:54:30.684715Z","shell.execute_reply.started":"2022-03-10T20:54:28.707019Z","shell.execute_reply":"2022-03-10T20:54:30.68389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:30:27.429011Z","iopub.execute_input":"2022-03-07T21:30:27.429433Z","iopub.status.idle":"2022-03-07T21:30:27.447576Z","shell.execute_reply.started":"2022-03-07T21:30:27.429399Z","shell.execute_reply":"2022-03-07T21:30:27.446949Z"}}},{"cell_type":"code","source":"rf_shap_values = rf_bl_exp.shap_values(val_X)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:31:29.584245Z","iopub.execute_input":"2022-03-07T21:31:29.584516Z","iopub.status.idle":"2022-03-07T21:32:09.988976Z","shell.execute_reply.started":"2022-03-07T21:31:29.584488Z","shell.execute_reply":"2022-03-07T21:32:09.987887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:33:52.283427Z","iopub.execute_input":"2022-03-07T21:33:52.284334Z","iopub.status.idle":"2022-03-07T21:33:52.291285Z","shell.execute_reply.started":"2022-03-07T21:33:52.284274Z","shell.execute_reply":"2022-03-07T21:33:52.290279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------------\n# Interpreting Single Models\n# ----------------------\nval_X = X_train\nsmall_val_X = X_train.iloc[:150]","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:08:27.758868Z","iopub.execute_input":"2022-03-07T21:08:27.759159Z","iopub.status.idle":"2022-03-07T21:08:27.764381Z","shell.execute_reply.started":"2022-03-07T21:08:27.759129Z","shell.execute_reply":"2022-03-07T21:08:27.763035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lasso_pipeline.fit(X_n2, y_n2)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:04:38.734704Z","iopub.execute_input":"2022-03-10T21:04:38.735038Z","iopub.status.idle":"2022-03-10T21:04:39.357192Z","shell.execute_reply.started":"2022-03-10T21:04:38.734994Z","shell.execute_reply":"2022-03-10T21:04:39.35612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_bl_exp = shap.TreeExplainer(rf_bl)\nhgb_bl_exp = shap.TreeExplainer(hgb_bl)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T21:09:20.930459Z","iopub.execute_input":"2022-03-10T21:09:20.930731Z","iopub.status.idle":"2022-03-10T21:09:20.966097Z","shell.execute_reply.started":"2022-03-10T21:09:20.930699Z","shell.execute_reply":"2022-03-10T21:09:20.965249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#v_reg_exp = shap.TreeExplainer(vote_reg)\nlasso_bl_exp = shap.Explainer(lasso_pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T22:57:15.044225Z","iopub.execute_input":"2022-03-10T22:57:15.045238Z","iopub.status.idle":"2022-03-10T22:57:15.160426Z","shell.execute_reply.started":"2022-03-10T22:57:15.045197Z","shell.execute_reply":"2022-03-10T22:57:15.159047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_summary(rf_bl_exp)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T22:00:40.913966Z","iopub.execute_input":"2022-03-07T22:00:40.914264Z","iopub.status.idle":"2022-03-07T22:01:22.784466Z","shell.execute_reply.started":"2022-03-07T22:00:40.914232Z","shell.execute_reply":"2022-03-07T22:01:22.783479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_summary(hgb_bl_exp)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T22:01:22.786499Z","iopub.execute_input":"2022-03-07T22:01:22.786841Z","iopub.status.idle":"2022-03-07T22:01:25.950974Z","shell.execute_reply.started":"2022-03-07T22:01:22.78679Z","shell.execute_reply":"2022-03-07T22:01:25.950012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_force(20, )","metadata":{"execution":{"iopub.status.busy":"2022-03-10T20:54:53.754581Z","iopub.execute_input":"2022-03-10T20:54:53.754862Z","iopub.status.idle":"2022-03-10T20:54:53.811247Z","shell.execute_reply.started":"2022-03-10T20:54:53.75483Z","shell.execute_reply":"2022-03-10T20:54:53.809887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_force(20, rf_bl_exp)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:38:38.29793Z","iopub.execute_input":"2022-03-08T22:38:38.298376Z","iopub.status.idle":"2022-03-08T22:38:38.357389Z","shell.execute_reply.started":"2022-03-08T22:38:38.298328Z","shell.execute_reply":"2022-03-08T22:38:38.356762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_force(20, xgb_bl_exp)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:39:11.585654Z","iopub.execute_input":"2022-03-08T22:39:11.585974Z","iopub.status.idle":"2022-03-08T22:39:11.934461Z","shell.execute_reply.started":"2022-03-08T22:39:11.585946Z","shell.execute_reply":"2022-03-08T22:39:11.933246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# problem solving the XGB Shapley Values\n# xgb_y_preds = xgb_bl.predict(X_train)\nxgb_bl_exp = shap.TreeExplainer(xgb_bl)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T22:38:58.408761Z","iopub.execute_input":"2022-03-08T22:38:58.409449Z","iopub.status.idle":"2022-03-08T22:39:01.063498Z","shell.execute_reply.started":"2022-03-08T22:38:58.409385Z","shell.execute_reply":"2022-03-08T22:39:01.06278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shap_force(10, xgb_bl_exp)\nrow_to_show = 10\nval_X = X_train\nsmall_val_X = X_train.iloc[:150]\n\ndata_investigate = val_X.iloc[row_to_show]\n\nshap_values = xgb_bl_exp.shap_values(data_investigate, check_additivity=False)\n\n# display shap value graphic\n# shap.initjs()\n# shap.force_plot(explainer.expected_value, shap_values[0], data_investigate)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T21:51:52.99206Z","iopub.execute_input":"2022-03-07T21:51:52.992822Z","iopub.status.idle":"2022-03-07T21:51:53.379131Z","shell.execute_reply.started":"2022-03-07T21:51:52.992786Z","shell.execute_reply":"2022-03-07T21:51:53.377573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values, small_val_X, plot_type='bar')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:01:41.650647Z","iopub.status.idle":"2022-03-05T23:01:41.658277Z","shell.execute_reply.started":"2022-03-05T23:01:41.657973Z","shell.execute_reply":"2022-03-05T23:01:41.65801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_of_interest = 'Feature1'\ninteraction_feature = 'MedNgbdArea'\nshap.dependence_plot(feature_of_interest, shap_values, small_val_X, interaction_index=interaction_feature)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:01:41.659461Z","iopub.status.idle":"2022-03-05T23:01:41.659968Z","shell.execute_reply.started":"2022-03-05T23:01:41.65976Z","shell.execute_reply":"2022-03-05T23:01:41.65978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_of_interest = 'LotArea'\ninteraction_feature = 'GrLivArea'\nshap.dependence_plot(feature_of_interest, shap_values, small_val_X, interaction_index=interaction_feature)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:01:41.660957Z","iopub.status.idle":"2022-03-05T23:01:41.661418Z","shell.execute_reply.started":"2022-03-05T23:01:41.661234Z","shell.execute_reply":"2022-03-05T23:01:41.661253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_for_prediction = val_X.iloc[0,:]  # use 1 row of data here. Could use multiple rows if desired\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(my_model)\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)\n# ------------","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.809736Z","iopub.status.idle":"2022-03-04T23:55:03.810248Z","shell.execute_reply.started":"2022-03-04T23:55:03.809996Z","shell.execute_reply":"2022-03-04T23:55:03.810023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summarizing Shapley Values","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.811958Z","iopub.status.idle":"2022-03-04T23:55:03.812412Z","shell.execute_reply.started":"2022-03-04T23:55:03.812167Z","shell.execute_reply":"2022-03-04T23:55:03.812191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data_for_prediction\ndata_investigate","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.814047Z","iopub.status.idle":"2022-03-04T23:55:03.814504Z","shell.execute_reply.started":"2022-03-04T23:55:03.814253Z","shell.execute_reply":"2022-03-04T23:55:03.814279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer.expected_value\ndata_investigate.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.816538Z","iopub.status.idle":"2022-03-04T23:55:03.817268Z","shell.execute_reply.started":"2022-03-04T23:55:03.817051Z","shell.execute_reply":"2022-03-04T23:55:03.817076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n--- \n\n## Individual and Blended Models\n---\n---","metadata":{}},{"cell_type":"code","source":"#---------------------------\n# My Data Pipeline \n# ---------------------------\n\nX_train, X_test, y_train = prepare_stacked_data()\ndata_reference = (X_train, X_test, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.748108Z","iopub.status.idle":"2022-03-04T23:55:03.748425Z","shell.execute_reply.started":"2022-03-04T23:55:03.748268Z","shell.execute_reply":"2022-03-04T23:55:03.748284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=0, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.738124Z","iopub.status.idle":"2022-03-04T23:55:03.738435Z","shell.execute_reply.started":"2022-03-04T23:55:03.738276Z","shell.execute_reply":"2022-03-04T23:55:03.738292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------------------\n# Ridge Model Fitting\n# ------------------\n\nridge_rsearch = RandomizedSearchCV(ridge_model, param_distributions=ridge_param_dist, n_iter=n_iter_search)\nridge_rsearch.fit(X_train, y_train)\nridge_b_model = rf_gsearch.best_estimator_\nridge_score = ridge_rsearch.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.758555Z","iopub.status.idle":"2022-03-04T23:55:03.758964Z","shell.execute_reply.started":"2022-03-04T23:55:03.758736Z","shell.execute_reply":"2022-03-04T23:55:03.758759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------------------\n# SVR Model Fitting\n# ------------------\n\nsvr_rsearch = RandomizedSearchCV(svr_model, param_distributions=svr_param_dist, n_iter=n_iter_search)\nsvr_rsearch.fit(X_train, y_train)\nsvr_b_model = svr_rsearch.best_estimator\nsvr_score = svr_rsearch.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.760152Z","iopub.status.idle":"2022-03-04T23:55:03.760969Z","shell.execute_reply.started":"2022-03-04T23:55:03.760726Z","shell.execute_reply":"2022-03-04T23:55:03.76076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---- \n----\n# Old Code\n----\n----","metadata":{}},{"cell_type":"code","source":"# -------------\n# Aside: note\n# -------------\n\n# scipy uniform understanding \n# import matplotlib.pyplot as plt\n# r = uniform.rvs(loc=1, scale=4, size=1000)\n\n# fig, ax = plt.subplots(1, 1)\n# ax.hist(r, density=True, histtype='stepfilled', alpha=0.2)\n# ax.legend(loc='best', frameon=False)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.742622Z","iopub.status.idle":"2022-03-04T23:55:03.743023Z","shell.execute_reply.started":"2022-03-04T23:55:03.742822Z","shell.execute_reply":"2022-03-04T23:55:03.742846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------\n# Hyper Parameter Tuning for Individual Models\n# --------------------------------------\nfrom scipy.stats import uniform \n\n# XGBoost Model Setup\nxgb_model = XGBRegressor(\n                   objective='reg:squarederror',\n                   nthread=-1,\n                   scale_pos_weight=1,\n                   seed=11,\n                   random_state=2\n                   )\n\nxgb_param_dist = dict(learning_rate= uniform(0.005, 0.1),\n                   n_estimators=1000*np.arange(4,14,2),\n                   max_depth=np.arange(4,6,1),\n                   min_child_weight=np.arange(0, 1, 0.1),\n                   gamma=uniform(0.3,0.8),\n                   subsample= uniform(0.4,1),\n                   colsample_bytree= uniform(0.6,1),\n                   reg_alpha=uniform(0.00001, 0.0001)\n                   )\n\n\nxgb_param_grid = dict(learning_rate= np.arange(0.005, 0.1, 0.005),\n                   n_estimators=1000*np.arange(4,14,2),\n                   max_depth=np.arange(4,6,1),\n                   min_child_weight=np.arange(0, 1, 0.1),\n                   gamma=np.arange(0.3,0.8,0.1),\n                   subsample= np.arange(0.6, 1.1, 0.1),\n                   colsample_bytree= np.arange(0.6, 1.1, 0.1),\n                   reg_alpha=np.linspace(0.00001, 0.0001)\n                   )\n\n# Random Forest Model Setup\nrf_model = RandomForestRegressor(max_features=None,\n                    oob_score=True,\n                    random_state=42\n                    )\n\nrf_param_grid = dict(n_estimators=np.arange(800,1200,200),\n                    max_depth=np.arange(7,20),\n                    min_samples_split=np.arange(3,10),\n                    min_samples_leaf=np.arange(3,7,1),\n                    )\n\n# Ridge Model Setup\nridge_model = Ridge(solver='lsqr')\n\nridge_param_dist = dict(alphas = uniform(1e-15, 100))\n\n# SVR Model Setup\nsvr_model = SVR()\n\nsvr_param_dist = dict(C=uniform(0.01, 10), \n                      epsilon= uniform(0.001,0.5)\n                     )\n\n# Todo: Decide if we will use these\n# lasso model setup\n# elastic model setup","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.744571Z","iopub.status.idle":"2022-03-04T23:55:03.744923Z","shell.execute_reply.started":"2022-03-04T23:55:03.744716Z","shell.execute_reply":"2022-03-04T23:55:03.744732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------------------\n# Optuna enet\n\ndef objective(trial):\n    enet_params = dict(\n        alpha=trial.suggest_float(\"alpha\", 1e-3, 10.0),\n        l1_ratio=trial.suggest_float(\"l1_ratio\", 0.01, 1.0),\n    )\n    \n    enet = ElasticNet(**enet_params)\n    return score_dataset(X_train, y_train, ridge_model, enc=False, trans_targ=False)\n\nenet_study = optuna.create_study(direction=\"minimize\")\nenet_study.optimize(objective, n_trials=3)\nenet_params_tuna = ridge_study.best_params\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T00:32:16.323207Z","iopub.execute_input":"2022-03-05T00:32:16.3239Z","iopub.status.idle":"2022-03-05T00:32:16.463632Z","shell.execute_reply.started":"2022-03-05T00:32:16.323863Z","shell.execute_reply":"2022-03-05T00:32:16.462787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------------------\n# XGB Model Fitting\n# ------------------\n\nn_iter_search = 15\nxgb_rsearch = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_dist, n_iter=n_iter_search)\nxgb_rsearch.fit(X_train, y_train)\nxgb_b_model = xgb_rsearch.best_estimator_\nxgb_score = xgb_rsearch.best_score_\nprint(xgb_score)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.749951Z","iopub.status.idle":"2022-03-04T23:55:03.750265Z","shell.execute_reply.started":"2022-03-04T23:55:03.750103Z","shell.execute_reply":"2022-03-04T23:55:03.750119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cv_rmse(xgb_b_model, X_train, y_train))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.753101Z","iopub.status.idle":"2022-03-04T23:55:03.753403Z","shell.execute_reply.started":"2022-03-04T23:55:03.753242Z","shell.execute_reply":"2022-03-04T23:55:03.753257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ------------------\n# Random Forest Model Fitting\n# ------------------\n\nrf_gsearch = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=n_iter_search)\nrf_gsearch.fit(X_train, y_train)\nrf_b_model = rf_gsearch.best_estimator_\nrf_score = rf_gsearch.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.754634Z","iopub.status.idle":"2022-03-04T23:55:03.75498Z","shell.execute_reply.started":"2022-03-04T23:55:03.754792Z","shell.execute_reply":"2022-03-04T23:55:03.754828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_dataset(X_train, y_train, rf_b_model, enc=False, trans_targ=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.756652Z","iopub.status.idle":"2022-03-04T23:55:03.757207Z","shell.execute_reply.started":"2022-03-04T23:55:03.756991Z","shell.execute_reply":"2022-03-04T23:55:03.757018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------------------------\n# Blended Model\n#------------------------\n\n# sklearn version \"VotingRegressor\"\nfrom sklearn.ensemble import VotingRegressor\n\nreg_models = {'xgb': {'model': xgb_b_model, 'weight': 0.2},\n              #'lasso': {'model': lasso_b_model, 'weight': 0.2},\n              'rforest': {'model': rf_b_model, 'weight': 0.2},\n              'ridge': {'model': ridge_b_model, 'weight': 0.2},\n              'svr'  : {'model': svr_b_model, 'weight': 0.2},\n              'stacked': {'model': stacked_model, 'weight': 0.2}}\n\nreg_models = [(key, value['model']) for key, value in models_dict.items()]\nvote_weights = [value['weight'] for value in models_dict.values()]\n\nvote_reg = VotingRegressor(estimators=reg_models, weights=vote_weights)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.76187Z","iopub.status.idle":"2022-03-04T23:55:03.762505Z","shell.execute_reply.started":"2022-03-04T23:55:03.762298Z","shell.execute_reply":"2022-03-04T23:55:03.762325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n---\n---\n# Sub Chapter: Linear Model Experiment\n---\n---\n---","metadata":{}},{"cell_type":"code","source":"# ------------------\n# Ridge Model Fitting\n# ------------------\n\n# Setup cross validation folds\nkf = KFold(n_splits=12, random_state=0, shuffle=True)\n\nridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\nridge_solo_pipe = make_pipeline(linear_preprocessor, RidgeCV(alphas=ridge_alphas, cv=kf))\nridge_solo_pipe.fit(X_train, y_train)\nridge_solo_pipe.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.763911Z","iopub.status.idle":"2022-03-04T23:55:03.764229Z","shell.execute_reply.started":"2022-03-04T23:55:03.764062Z","shell.execute_reply":"2022-03-04T23:55:03.764084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1_ratios = [.1, .5, .7, .9, .95, .99, 1]\nelastic_solo_pipe = make_pipeline(linear_preprocessor, ElasticNetCV(l1_ratio=l1_ratios ,cv=kf))\nelastic_solo_pipe.fit(X_train, y_train)\nelastic_solo_pipe.score(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.765639Z","iopub.status.idle":"2022-03-04T23:55:03.766215Z","shell.execute_reply.started":"2022-03-04T23:55:03.766004Z","shell.execute_reply":"2022-03-04T23:55:03.76603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# end: linear sub Chapter\n\n---\n---\n---","metadata":{}},{"cell_type":"code","source":"# ------------------\n# Ridge Model Fitting\n# ------------------\nridge_rsearch = RandomizedSearchCV(ridge_model, param_distributions=ridge_param_dist, n_iter=n_iter_search)\n\nridge_rsearch.fit(X_train, y_train)\nridge_b_model = rf_gsearch.best_estimator_\nridge_score = ridge_rsearch.best_score_","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.767459Z","iopub.status.idle":"2022-03-04T23:55:03.767789Z","shell.execute_reply.started":"2022-03-04T23:55:03.76761Z","shell.execute_reply":"2022-03-04T23:55:03.767635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Light Gradient Boosting Regressor\nlightgbm = LGBMRegressor(objective='regression', \n                       num_leaves=6,\n                       learning_rate=0.01, \n                       n_estimators=7000,\n                       max_bin=200, \n                       bagging_fraction=0.8,\n                       bagging_freq=4, \n                       bagging_seed=8,\n                       feature_fraction=0.2,\n                       feature_fraction_seed=8,\n                       min_sum_hessian_in_leaf = 11,\n                       verbose=-1,\n                       random_state=42)\n\n# XGBoost Regressor\nxgboost = XGBRegressor(learning_rate=0.01,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:linear',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\n\n# Ridge Regressor\nridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))\n\n# Support Vector Regressor\nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n\n# Gradient Boosting Regressor\ngbr = GradientBoostingRegressor(n_estimators=6000,\n                                learning_rate=0.01,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=15,\n                                min_samples_split=10,\n                                loss='huber',\n                                random_state=42)  \n\n# Random Forest Regressor\nrf = RandomForestRegressor(n_estimators=1200,\n                          max_depth=15,\n                          min_samples_split=5,\n                          min_samples_leaf=5,\n                          max_features=None,\n                          oob_score=True,\n                          random_state=42)\n\n# Stack up all the models above, optimized using xgboost\nstack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, rf),\n                                meta_regressor=xgboost,\n                                use_features_in_secondary=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.769362Z","iopub.status.idle":"2022-03-04T23:55:03.769705Z","shell.execute_reply.started":"2022-03-04T23:55:03.769529Z","shell.execute_reply":"2022-03-04T23:55:03.769552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------\n# Fit the final 0.3 models\n# -----------------------","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.782259Z","iopub.status.idle":"2022-03-04T23:55:03.782747Z","shell.execute_reply.started":"2022-03-04T23:55:03.782508Z","shell.execute_reply":"2022-03-04T23:55:03.782536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('stack_gen')\nstack_gen_model = stack_gen.fit(np.array(X), np.array(train_labels))","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.783765Z","iopub.status.idle":"2022-03-04T23:55:03.784147Z","shell.execute_reply.started":"2022-03-04T23:55:03.783957Z","shell.execute_reply":"2022-03-04T23:55:03.783974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('lightgbm')\nlgb_model_full_data = lightgbm.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.784883Z","iopub.status.idle":"2022-03-04T23:55:03.785178Z","shell.execute_reply.started":"2022-03-04T23:55:03.785022Z","shell.execute_reply":"2022-03-04T23:55:03.785038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('xgboost')\nxgb_model_full_data = xgboost.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.786061Z","iopub.status.idle":"2022-03-04T23:55:03.786377Z","shell.execute_reply.started":"2022-03-04T23:55:03.786206Z","shell.execute_reply":"2022-03-04T23:55:03.786222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Svr')\nsvr_model_full_data = svr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.787943Z","iopub.status.idle":"2022-03-04T23:55:03.78828Z","shell.execute_reply.started":"2022-03-04T23:55:03.788097Z","shell.execute_reply":"2022-03-04T23:55:03.788114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Ridge')\nridge_model_full_data = ridge.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.789249Z","iopub.status.idle":"2022-03-04T23:55:03.78961Z","shell.execute_reply.started":"2022-03-04T23:55:03.789446Z","shell.execute_reply":"2022-03-04T23:55:03.789463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('RandomForest')\nrf_model_full_data = rf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.790475Z","iopub.status.idle":"2022-03-04T23:55:03.790776Z","shell.execute_reply.started":"2022-03-04T23:55:03.790616Z","shell.execute_reply":"2022-03-04T23:55:03.790632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('GradientBoosting')\ngbr_model_full_data = gbr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.791902Z","iopub.status.idle":"2022-03-04T23:55:03.792218Z","shell.execute_reply.started":"2022-03-04T23:55:03.792057Z","shell.execute_reply":"2022-03-04T23:55:03.792073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------------\n# Blended Model 0.3\n# -----------------------\n\n# sklearn version \"VotingRegressor\"\nfrom sklearn.ensemble import VotingRegressor\n\nreg_models = {'xgb': {'model': xgb_model, 'weight', 0.2},\n              'lasso': {'model': lasso_model, 'weight': 0.2},\n              'ridge': {'model': ridge_model, 'weight': 0.2},\n              'svr'  : {'model': svr_model, 'weight': 0.2},\n              'stacked': {'model': stacked_model, 'weight': 0.2}}\n\nreg_models = [(key, value['model']) for key, value in models_dict.items()]\nvote_weights = [value['weight'] for value in models_dict.values()]\n\nvote_reg = VotingRegressor(estimators=reg_models, weights=vote_weights)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.793194Z","iopub.status.idle":"2022-03-04T23:55:03.793505Z","shell.execute_reply.started":"2022-03-04T23:55:03.793341Z","shell.execute_reply":"2022-03-04T23:55:03.793358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get final precitions from the blended model\nblended_score = rmsle(y_train, VotingRegressor.fit(X_train))\nscores['blended'] = (blended_score, 0)\nprint('RMSLE score on train data:')\nprint(blended_score)","metadata":{"execution":{"iopub.status.busy":"2022-03-04T23:55:03.794724Z","iopub.status.idle":"2022-03-04T23:55:03.795038Z","shell.execute_reply.started":"2022-03-04T23:55:03.794879Z","shell.execute_reply":"2022-03-04T23:55:03.794894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n---\n---\n# Model Interpretation\n---\n---\n---","metadata":{}}]}